{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinakeshvari/Alcoholic_CNN_Classification/blob/main/Project02_DS04_S02_WordEmbedding_RezaShokrzad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📰 News Article Similarity Analysis using NLP 🧠📊\n",
        "\n",
        "## 🎯 Objective\n",
        "This notebook explores text similarity among news articles using NLP techniques. We will:\n",
        "\n",
        "✅ Convert text into numerical vectors using pre-trained **GloVe embeddings**.  \n",
        "✅ Reduce dimensionality for visualization using **PCA**.  \n",
        "✅ Apply **K-Means clustering** to group similar news articles.  \n",
        "\n",
        "---\n",
        "\n",
        "## 🔍 Why GloVe?\n",
        "GloVe (**Global Vectors for Word Representation**) provides **dense vector embeddings** trained on a large corpus, allowing us to capture the **semantic meaning** of words efficiently. 🏆✨  \n",
        "\n",
        "Using GloVe, we can **transform text into meaningful numerical representations** for further processing and clustering. 🚀📖\n"
      ],
      "metadata": {
        "id": "81F8Yu38bxwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📥 Import necessary libraries\n",
        "# ⬇️ Download stopwords for text cleaning\n",
        "\n"
      ],
      "metadata": {
        "id": "TMmGkOAkbxky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 Data Overview\n",
        "The dataset consists of news articles with the following columns:\n",
        "\n",
        "📰 **title**: The headline of the news article.  \n",
        "📄 **content**: The full text of the article.  \n",
        "\n",
        "🎯 Our goal is to **analyze the similarity between articles** and **group them into clusters** for better understanding. 🔍🤖  \n"
      ],
      "metadata": {
        "id": "hx4OHOf2b3lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# download the dataset\n",
        "!wget https://raw.githubusercontent.com/mage-ai/datasets/refs/heads/master/news_articles.csv\n"
      ],
      "metadata": {
        "id": "Iji0XRKmhHB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset\n",
        "\n",
        "# Display basic dataset information\n"
      ],
      "metadata": {
        "id": "mWB47xZzehTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🛠️ Text Preprocessing\n",
        "✅ **Lowercasing** to standardize words. 🔡  \n",
        "✅ **Removing special characters and punctuation** to clean the text. ✂️🧹  \n"
      ],
      "metadata": {
        "id": "G9HNIBxhcCsx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "# Handling missing values\n",
        "\n",
        "# Text Cleaning Function\n",
        "# Lowercasing\n",
        "# Remove non-word characters\n",
        "\n",
        "\n",
        "\n",
        "#apply the above function on the dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏆 GloVe-Based Embeddings  \n",
        "Each article is converted into a **100-dimensional numerical vector** using **GloVe embeddings**. 🔢✨  \n",
        "\n",
        "🔹 If a word is **found** in GloVe, its corresponding **vector** is used. ✅  \n",
        "🔹 If **no words** in an article match the GloVe vocabulary, a **zero vector** is assigned. ⚠️0️⃣  \n",
        "\n",
        "Using these vectors, we can numerically represent text for further **analysis and clustering**. 📊🔍🚀  \n"
      ],
      "metadata": {
        "id": "J6pHTsaecJO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load GloVe Embeddings\n",
        "glove_path = \"glove/glove.6B.100d.txt\"  # Change if using a different version\n"
      ],
      "metadata": {
        "id": "UfWCxxQ5cEDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert articles to vectors\n",
        "\n"
      ],
      "metadata": {
        "id": "5z59rGsrcHnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ℹ️ Understanding PCA for Dimensionality Reduction  \n",
        "\n",
        "### Why PCA? 🤔  \n",
        "When working with **high-dimensional data**, it’s difficult to visualize and analyze patterns. **Principal Component Analysis (PCA)** helps by reducing the number of dimensions while **preserving important information**.  \n",
        "\n",
        "### How Does It Work? ⚙️  \n",
        "PCA transforms our **high-dimensional word embeddings** (100 dimensions) into **2 principal components** that capture most of the variance in the data. This allows us to **visualize articles in a 2D space**, making clustering more interpretable.  \n",
        "\n",
        "🎯 **Goal:** Reduce dimensionality while retaining the most important information for better visualization and clustering.  \n",
        "📊 **Next Step:** We’ll plot the articles in a 2D space to see if meaningful patterns emerge! 🚀  \n"
      ],
      "metadata": {
        "id": "XHeatmrZetsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce to 2D for visualization\n",
        "\n",
        "\n",
        "# Store in DataFrame\n",
        "df['pca_x'] = X_pca[:, 0]\n",
        "df['pca_y'] = X_pca[:, 1]\n",
        "\n",
        "# display the result in 2d diagram\n",
        "\n"
      ],
      "metadata": {
        "id": "P73OnJkOcLOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ℹ️ Understanding K-Means Clustering  \n",
        "\n",
        "### Why Clustering? 🧐  \n",
        "Once we have numerical representations of articles, we want to **group similar news articles together** based on their content. **K-Means clustering** is a powerful unsupervised learning algorithm that does exactly this!  \n",
        "\n",
        "### How Does K-Means Work? ⚙️  \n",
        "1️⃣ Choose the number of clusters (**k**)  \n",
        "2️⃣ Assign each data point (news article) to the nearest cluster center  \n",
        "3️⃣ Recalculate the cluster centers based on assigned points  \n",
        "4️⃣ Repeat until cluster assignments stop changing  \n",
        "\n",
        "### Choosing the Right k 📊  \n",
        "We use the **Elbow Method** to find the **optimal number of clusters**. This helps prevent **overfitting** (too many clusters) or **underfitting** (too few clusters).  \n",
        "\n",
        "🎯 **Goal:** Assign each article to a cluster and visualize the grouping! Let’s see if similar news topics naturally emerge. 🔍📰  \n"
      ],
      "metadata": {
        "id": "wQCjPJLTew7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the optimal number of clusters using Elbow Method\n",
        "\n",
        "\n",
        "\n",
        "# display the result of elbow method\n",
        "\n"
      ],
      "metadata": {
        "id": "IrR9_JWwcS2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K-Means with optimal k (let's assume 4 based on the Elbow Method)\n",
        "\n",
        "\n",
        "# Visualizing Clusters\n",
        "\n"
      ],
      "metadata": {
        "id": "fz-Hfl8McUKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ℹ️ Visualizing Clusters with Word Clouds  (Optional Section)\n",
        "\n",
        "### Why Use Word Clouds? 🌥️🔠  \n",
        "After clustering the news articles, it’s helpful to **understand the key themes** in each cluster. A **word cloud** is a simple but effective way to visualize the most common words in each group.  \n",
        "\n",
        "### How Does It Work? ⚙️  \n",
        "1️⃣ We **extract the text** from all articles in a cluster.  \n",
        "2️⃣ We **count word frequencies**, giving more importance to frequently occurring words.  \n",
        "3️⃣ A **word cloud** is generated, where **larger words** indicate higher frequency in that cluster.  \n",
        "\n",
        "### What Can We Learn? 🤔  \n",
        "- Identify **dominant keywords** in each cluster.  \n",
        "- Get **insights into topic differences** between clusters.  \n",
        "- Verify if our **K-Means clustering makes sense** based on meaningful word groupings.  \n",
        "\n",
        "🎯 **Goal:** Use word clouds to quickly interpret the characteristics of each news category! ☁️📰🔍  \n"
      ],
      "metadata": {
        "id": "2BTgAHKqe30c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate word cloud\n",
        "\n",
        "\n",
        "# Generate for each cluster\n"
      ],
      "metadata": {
        "id": "oRcP5VpacVrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧐 Critical Thinking & Discussion: Interpreting Our Results 💡📊📰\n",
        "\n",
        "### 1️⃣ PCA Visualization Analysis\n",
        "#### 🔍 Question:\n",
        "Looking at the PCA Projection of News Articles, we see that the data is spread out but still has some overlapping areas.\n",
        "\n",
        "- What does this distribution tell us about the underlying structure of the articles?\n",
        "- Do you think reducing dimensionality to 2 components sufficiently preserves the key variations in the dataset? Why or why not?\n",
        "\n",
        "\n",
        "### 2️⃣ Choosing the Optimal Number of Clusters\n",
        "#### 📊 Question:\n",
        "The Elbow Method plot suggests a decreasing trend in distortion as k increases.\n",
        "\n",
        "- Based on the curve, what would you choose as the optimal k value?\n",
        "- Why does the distortion decrease as k increases, and why shouldn’t we always choose a very high k?\n",
        "\n",
        "### 3️⃣ Interpreting Clusters of News Articles\n",
        "#### 📰 Question:\n",
        "After applying K-Means clustering, the PCA-reduced plot shows four distinct clusters.\n",
        "\n",
        "- How well-separated do the clusters appear? Do they seem meaningful?\n",
        "- What possible themes might each cluster represent in terms of news content? How could we validate our assumptions about these themes?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Iy_gXNQxfQQW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}